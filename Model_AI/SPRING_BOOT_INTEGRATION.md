# ğŸ”— IntÃ©gration API Python â†” Backend Spring Boot

## Vue d'ensemble

L'API Python (FastAPI) et le Backend Spring Boot communiquent via HTTP/REST.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      HTTP/REST       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚  Spring Boot     â”‚
â”‚   (Angular)     â”‚                      â”‚   Backend        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â”‚ HTTP/REST
                                                  â”‚
                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                         â”‚  FastAPI Python  â”‚
                                         â”‚  (AI Model)      â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Configuration des URLs

### API Python
- **URL locale**: `http://localhost:8000`
- **URL Docker**: `http://ai-service:8000`

### Backend Spring Boot
- **URL locale**: `http://localhost:8080`
- **URL Docker**: `http://backend:8080`

---

## ğŸ”§ ImplÃ©mentation cÃ´tÃ© Spring Boot

### 1. Ajouter la dÃ©pendance dans `pom.xml`

```xml
<!-- WebClient pour appels HTTP asynchrones -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-webflux</artifactId>
</dependency>
```

### 2. CrÃ©er le DTO pour la requÃªte

```java
package com.simstruct.backend.dto;

import lombok.Data;
import lombok.AllArgsConstructor;
import lombok.NoArgsConstructor;

@Data
@AllArgsConstructor
@NoArgsConstructor
public class BuildingPredictionRequest {
    private Double numFloors;
    private Double floorHeight;
    private Integer numBeams;
    private Integer numColumns;
    private Double beamSection;
    private Double columnSection;
    private Double concreteStrength;
    private Double steelGrade;
    private Double windLoad;
    private Double liveLoad;
    private Double deadLoad;
}
```

### 3. CrÃ©er le DTO pour la rÃ©ponse

```java
package com.simstruct.backend.dto;

import lombok.Data;
import lombok.AllArgsConstructor;
import lombok.NoArgsConstructor;

@Data
@AllArgsConstructor
@NoArgsConstructor
public class PredictionResponse {
    private Double maxDeflection;
    private Double maxStress;
    private Double stabilityIndex;
    private Double seismicResistance;
    private String status;
}
```

### 4. CrÃ©er le service d'intÃ©gration

```java
package com.simstruct.backend.service;

import com.simstruct.backend.dto.BuildingPredictionRequest;
import com.simstruct.backend.dto.PredictionResponse;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;
import org.springframework.web.reactive.function.client.WebClient;
import reactor.core.publisher.Mono;

@Slf4j
@Service
public class AIPredictionService {

    private final WebClient webClient;

    // L'URL de l'API Python est configurable via application.properties
    public AIPredictionService(
            @Value("${ai.service.url:http://localhost:8000}") String aiServiceUrl) {
        this.webClient = WebClient.builder()
                .baseUrl(aiServiceUrl)
                .build();
    }

    /**
     * Appelle l'API Python pour obtenir une prÃ©diction
     * 
     * @param request Les paramÃ¨tres du bÃ¢timent
     * @return La prÃ©diction du modÃ¨le AI
     */
    public Mono<PredictionResponse> getPrediction(BuildingPredictionRequest request) {
        log.info("Calling AI API for prediction: {}", request);
        
        return webClient.post()
                .uri("/predict")
                .bodyValue(request)
                .retrieve()
                .bodyToMono(PredictionResponse.class)
                .doOnSuccess(response -> 
                    log.info("AI prediction received: {}", response))
                .doOnError(error -> 
                    log.error("Error calling AI API: {}", error.getMessage()));
    }

    /**
     * VÃ©rifie si l'API AI est accessible
     * 
     * @return true si l'API est en bonne santÃ©
     */
    public Mono<Boolean> checkHealth() {
        return webClient.get()
                .uri("/health")
                .retrieve()
                .bodyToMono(String.class)
                .map(response -> response.contains("healthy"))
                .onErrorReturn(false);
    }
}
```

### 5. CrÃ©er le contrÃ´leur REST

```java
package com.simstruct.backend.controller;

import com.simstruct.backend.dto.BuildingPredictionRequest;
import com.simstruct.backend.dto.PredictionResponse;
import com.simstruct.backend.service.AIPredictionService;
import io.swagger.v3.oas.annotations.Operation;
import io.swagger.v3.oas.annotations.tags.Tag;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;
import reactor.core.publisher.Mono;

import javax.validation.Valid;

@Slf4j
@RestController
@RequestMapping("/api/predictions")
@RequiredArgsConstructor
@Tag(name = "AI Predictions", description = "Endpoints pour les prÃ©dictions AI")
public class PredictionController {

    private final AIPredictionService aiPredictionService;

    /**
     * Obtenir une prÃ©diction structurale
     */
    @PostMapping
    @Operation(summary = "Obtenir une prÃ©diction AI")
    public Mono<ResponseEntity<PredictionResponse>> predict(
            @Valid @RequestBody BuildingPredictionRequest request) {
        
        log.info("Received prediction request: {}", request);
        
        return aiPredictionService.getPrediction(request)
                .map(ResponseEntity::ok)
                .onErrorReturn(ResponseEntity.internalServerError().build());
    }

    /**
     * VÃ©rifier la santÃ© de l'API AI
     */
    @GetMapping("/health")
    @Operation(summary = "VÃ©rifier la santÃ© de l'API AI")
    public Mono<ResponseEntity<String>> checkAIHealth() {
        return aiPredictionService.checkHealth()
                .map(healthy -> healthy 
                    ? ResponseEntity.ok("AI Service is healthy")
                    : ResponseEntity.status(503).body("AI Service is unavailable"));
    }
}
```

### 6. Configuration dans `application.properties`

```properties
# Configuration de l'API AI
ai.service.url=http://localhost:8000

# Pour Docker (dÃ©commentez en production)
# ai.service.url=http://ai-service:8000

# Timeout pour les appels Ã  l'API AI (en secondes)
spring.webflux.timeout=30
```

---

## ğŸ³ Configuration Docker Compose

Ajoutez le service AI dans votre `docker-compose.yml`:

```yaml
version: '3.8'

services:
  # Service AI Python
  ai-service:
    build:
      context: ./Model_AI
      dockerfile: Dockerfile
    container_name: simstruct-ai
    ports:
      - "8000:8000"
    networks:
      - simstruct-network
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - ./Model_AI/models:/app/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Backend Spring Boot
  backend:
    build:
      context: ./Backend/simstruct-backend
      dockerfile: Dockerfile
    container_name: simstruct-backend
    ports:
      - "8080:8080"
    depends_on:
      - postgres
      - ai-service
    networks:
      - simstruct-network
    environment:
      - SPRING_DATASOURCE_URL=jdbc:postgresql://postgres:5432/simstruct
      - AI_SERVICE_URL=http://ai-service:8000
  
  # PostgreSQL
  postgres:
    image: postgres:15
    container_name: simstruct-postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=simstruct
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=admin123
    networks:
      - simstruct-network
    volumes:
      - postgres-data:/var/lib/postgresql/data

networks:
  simstruct-network:
    driver: bridge

volumes:
  postgres-data:
```

---

## ğŸ“ CrÃ©er le Dockerfile pour l'API AI

CrÃ©ez `Model_AI/Dockerfile`:

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Copier les requirements
COPY requirements.txt .

# Installer les dÃ©pendances
RUN pip install --no-cache-dir -r requirements.txt

# Copier le code source
COPY src/ ./src/
COPY models/ ./models/

# Exposer le port
EXPOSE 8000

# DÃ©marrer l'API
CMD ["uvicorn", "src.api:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

## ğŸ§ª Tester l'intÃ©gration

### 1. Tester localement (sans Docker)

**Terminal 1 - DÃ©marrer l'API Python:**
```bash
cd Model_AI/src
start_api.bat
```

**Terminal 2 - DÃ©marrer Spring Boot:**
```bash
cd Backend/simstruct-backend
mvnw spring-boot:run
```

**Terminal 3 - Tester:**
```bash
curl -X POST http://localhost:8080/api/predictions \
  -H "Content-Type: application/json" \
  -d '{
    "numFloors": 10,
    "floorHeight": 3.5,
    "numBeams": 120,
    "numColumns": 36,
    "beamSection": 30,
    "columnSection": 40,
    "concreteStrength": 35,
    "steelGrade": 355,
    "windLoad": 1.5,
    "liveLoad": 3.0,
    "deadLoad": 5.0
  }'
```

### 2. Tester avec Docker

```bash
# Construire et dÃ©marrer tous les services
docker-compose up --build

# Dans un autre terminal, tester
curl -X POST http://localhost:8080/api/predictions \
  -H "Content-Type: application/json" \
  -d '{"numFloors": 10, ...}'
```

---

## ğŸ” Gestion des erreurs

### CÃ´tÃ© Spring Boot

```java
@ControllerAdvice
public class GlobalExceptionHandler {

    @ExceptionHandler(WebClientException.class)
    public ResponseEntity<String> handleWebClientException(WebClientException ex) {
        log.error("Error calling AI service: {}", ex.getMessage());
        return ResponseEntity.status(503)
            .body("AI service is temporarily unavailable");
    }
}
```

### Fallback en cas d'erreur

```java
public Mono<PredictionResponse> getPredictionWithFallback(
        BuildingPredictionRequest request) {
    return getPrediction(request)
        .onErrorResume(error -> {
            log.warn("AI service unavailable, using fallback");
            return Mono.just(createFallbackResponse());
        });
}

private PredictionResponse createFallbackResponse() {
    return new PredictionResponse(
        0.0, 0.0, 0.0, 0.0, 
        "Service temporarily unavailable"
    );
}
```

---

## ğŸ“Š Exemple de flux complet

```
1. Frontend Angular envoie une requÃªte:
   POST http://localhost:4200/api/simulations
   
2. Spring Boot reÃ§oit la requÃªte:
   POST http://localhost:8080/api/simulations
   
3. Spring Boot sauvegarde en base de donnÃ©es
   
4. Spring Boot appelle l'API Python:
   POST http://localhost:8000/predict
   
5. API Python retourne la prÃ©diction
   
6. Spring Boot met Ã  jour la simulation avec les rÃ©sultats
   
7. Spring Boot retourne la rÃ©ponse au Frontend
```

---

## âœ… Checklist d'intÃ©gration

- [ ] API Python fonctionne (`http://localhost:8000/docs`)
- [ ] Backend Spring Boot fonctionne (`http://localhost:8080`)
- [ ] WebClient configurÃ© dans Spring Boot
- [ ] DTOs crÃ©Ã©s (BuildingPredictionRequest, PredictionResponse)
- [ ] Service AIPredictionService crÃ©Ã©
- [ ] ContrÃ´leur PredictionController crÃ©Ã©
- [ ] application.properties configurÃ©
- [ ] Dockerfile crÃ©Ã© pour l'API Python
- [ ] docker-compose.yml mis Ã  jour
- [ ] Tests d'intÃ©gration rÃ©ussis

---

## ğŸ¯ Points importants

1. **Timeout**: Configurez un timeout appropriÃ© (30s recommandÃ©)
2. **Retry**: Ajoutez une logique de retry en cas d'Ã©chec temporaire
3. **Circuit Breaker**: Utilisez Resilience4j pour gÃ©rer les pannes
4. **Monitoring**: Ajoutez des logs et mÃ©triques
5. **Cache**: ConsidÃ©rez un cache pour les prÃ©dictions frÃ©quentes

---

*Guide d'intÃ©gration - SimStruct AI Project - 14 DÃ©cembre 2025*
